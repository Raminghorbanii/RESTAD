type: "Transformer_RBF"

base_model_type: "Transformer" # This is the type of the model in phase 1

#model configuration
input_size: ${dataset.x_dim}
d_model: 32
d_ff: 128
n_heads: 8
e_layers: 3

rbf_dim: 128

#Optimization configuration
batch_size: 64
num_epochs: 10

lr: 1e-2
weight_decay:  1e-5
dropout: 0
clip_grad: 3

rbfScore_regFactor: 0




# Optimized HyperParameters: 
    # PSM:  d_model = 32
    #       d_ff = 128
    #       n_heads: 8

    #       rbf = 32
    #       batch_size = 64
    #       num_epochs = 100
    #       lr = 1e-2
    #       w_d: 1e-3
    #       dropout: 0.5
    #       clip_grad: 3
    #       rbfscore_landa: 0
    


# Optimized HyperParameters: 
    # MSL:  d_model = 32
    #       d_ff = 128
    #       n_heads: 8

    #       rbf = 128
    #       batch_size = 64
    #       num_epochs = 100
    #       lr = 1e-2
    #       w_d: 1e-5
    #       dropout: 0
    #       clip_grad: 3
    #       rbfscore_landa: 0
    
    


# Optimized HyperParameters: 
    # SMD:  d_model = 32
    #       d_ff = 128
    #       n_heads: 8
    
    #       rbf = 256
    #       batch_size = 64
    #       num_epochs = 100
    #       lr = 1e-2
    #       w_d: 1e-3
    #       dropout: 0
    #       clip_grad: 1.5
    #       rbfscore_landa: 0
    
    


#############


# Optimized HyperParameters: 
    # SMD Kmeans:  d_model = 32
    #       d_ff = 128
    #       n_heads: 8
    
    #       rbf = 32
    #       batch_size = 64
    #       num_epochs = 100
    #       lr = 1e-2
    #       w_d: 1e-5
    #       dropout: 0
    #       clip_grad: 3
    #       rbfscore_landa: 0
    


# Optimized HyperParameters: 
    # PSM k means:  d_model = 32
    #       d_ff = 256
    #       n_heads: 8

    #       rbf = 16
    #       batch_size = 64
    #       num_epochs = 100
    #       lr = 1e-2
    #       w_d: 1e-3
    #       dropout: 0.3
    #       clip_grad: 1.5
    #       rbfscore_landa: 0
    

# Optimized HyperParameters: 
    # MSL kmeans:  d_model = 32
    #       d_ff = 128
    #       n_heads: 8

    #       rbf = 8
    #       batch_size = 64
    #       num_epochs = 100
    #       lr = 1e-1
    #       w_d: 1e-1
    #       dropout: 0.3
    #       clip_grad: 3
    #       rbfscore_landa: 0




#######################################
#######################################
#######################################
#######################################
